{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b82d405-5b5a-4698-9642-8e48cd6d399b",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d2952-5e1d-40b4-85b4-0aadc3acd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from visualkeras import layered_view\n",
    "from keras.datasets import mnist, fashion_mnist, cifar10\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from gand.config import MLConfig\n",
    "from gand.data import data\n",
    "from gand.models import models, architecture\n",
    "from gand.visualisation import visualise\n",
    "from gand.preprocessing import utils\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21720435-f5b2-4934-b7f1-6db9f4b98214",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e8e26-1b23-4a2f-b587-ad74db5fd496",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = MLConfig.BATCH_SIZE\n",
    "\n",
    "loss = \"categorical_crossentropy\"\n",
    "opt = tf.keras.optimizers.legacy.SGD(learning_rate=0.0001, momentum=0.9)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "g_model_mnist = load_model(Path.cwd() / 'notebooks/models/cgan/mnist/gen_model_e-200.h5')\n",
    "g_model_fashion_mnist = load_model(Path.cwd() / 'notebooks/models/cgan/fashion_mnist/gen_model_e-536.h5')\n",
    "g_model_cifar10 = load_model(Path.cwd() / 'notebooks/models/cgan/cifar10/gen_model_e-553.h5')\n",
    "g_model = g_model_mnist\n",
    "\n",
    "train_with_gan = False\n",
    "imbalance_data = False\n",
    "train_type = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093417a5-ccb0-462b-ac94-d007f5cfdd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'normal'\n",
    "if train_with_gan:\n",
    "    name = 'gans'\n",
    "elif imbalance_data:\n",
    "    name = 'imbalanced'\n",
    "\n",
    "MLConfig.TYPE_NAMES = [f'{name}']\n",
    "print(MLConfig.TYPE_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4f021-8524-44c2-8a8c-723d5a4542f7",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd27f19-113d-4e34-95c5-a4b2a73e4e2f",
   "metadata": {},
   "source": [
    "### GAN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466416c-0523-4dd8-9a14-113616d2cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gan, y_train_gan = None, None\n",
    "if train_with_gan:\n",
    "    imbalance_data = True\n",
    "    # GAN DATA\n",
    "    n = 4000\n",
    "    X_train_gan, y_train_gan = data.generate_fake_data(n=n, g_model=g_model, seed=10, verbose=1)\n",
    "    X_train_gan, y_train_gan = utils.preprocess_data(X_train_gan, y_train_gan, val_255=False, exp_dims=False)\n",
    "    \n",
    "    print(X_train_gan.min(), X_train_gan.max(), X_train_gan.shape, y_train_gan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6acd29c-a8ea-437e-b5bd-b5ac9580b06b",
   "metadata": {},
   "source": [
    "### Normal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747973a6-fd11-41ce-9024-e53644337ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_train_real, y_train_real), (X_test_real, y_test_real)), dataset_name = data.load_dataset(dataset, return_name=True)\n",
    "print(X_train_real.shape, y_train_real.shape, X_test_real.shape, y_test_real.shape, dataset_name)\n",
    "\n",
    "exp_dims = False\n",
    "if len(X_train_real.shape) == 3:\n",
    "    exp_dims = True\n",
    "\n",
    "\n",
    "print(X_train_real.min(), X_train_real.max(), X_test_real.min(), X_test_real.max())\n",
    "\n",
    "X_train_real, y_train_real = utils.preprocess_data(X_train_real, y_train_real, exp_dims=exp_dims)\n",
    "X_test_real, y_test_real = utils.preprocess_data(X_test_real, y_test_real, exp_dims=exp_dims)\n",
    "\n",
    "print(X_train_real.min(), X_train_real.max(), X_test_real.min(), X_test_real.max())\n",
    "print(X_train_real.shape, y_train_real.shape, X_test_real.shape, y_test_real.shape, dataset_name)\n",
    "\n",
    "if imbalance_data:\n",
    "    # REMOVING 75%\n",
    "    keep_per_class = 1000\n",
    "    X_train_removed, y_train_removed = [], []\n",
    "    for i in range(y_train_real.shape[-1]):\n",
    "        class_idx = np.where(np.argmax(y_train_real, axis=-1) == i)[0]\n",
    "        selected_idx = np.random.choice(class_idx, keep_per_class)\n",
    "        X_train_removed.append(X_train_real[selected_idx])\n",
    "        y_train_removed.append(y_train_real[selected_idx])\n",
    "    \n",
    "    X_train_real, y_train_real = np.concatenate(X_train_removed, axis=0), np.concatenate(y_train_removed, axis=0)\n",
    "print(X_train_real.shape, y_train_real.shape, X_test_real.shape, y_test_real.shape, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c7622-8f8e-4025-9606-38759ff077ab",
   "metadata": {},
   "source": [
    "### Appending GAN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1edde-118d-466c-8e8a-68f655bde67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_with_gan:\n",
    "    X_train_real = np.concatenate((X_train_real, X_train_gan), axis=0)\n",
    "    y_train_real = np.concatenate((y_train_real, y_train_gan), axis=0)\n",
    "    print(X_train_real.shape, y_train_real.shape, X_test_real.shape, y_test_real.shape, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d447a9-0ec3-4627-b4a0-ba40880361c8",
   "metadata": {},
   "source": [
    "### Shuffle It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2616c-fb65-4612-b466-97f865103b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_real, y_train_real = shuffle(X_train_real, y_train_real)\n",
    "X_test_real, y_test_real = shuffle(X_test_real, y_test_real)\n",
    "print(X_train_real.shape, y_train_real.shape, X_test_real.shape, y_test_real.shape, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291673e-cbf5-494e-ad24-276f57a1abf1",
   "metadata": {},
   "source": [
    "### Make it Faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be991fbf-6c9f-4892-aaa2-606a9bfeb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train_real, y_train_real))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test_real, y_test_real))\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = test_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_data, test_data, dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22051162-85e0-41bf-a4f6-bb49b8fc11b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLConfig.TYPE_NAMES[train_type], X_train_real.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd5658-e9cf-4f7f-b8ea-910ee375447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = architecture.deep_model(img_shape=X_train_real.shape[1:])\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "model.name, EPOCHS, BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dda132-1647-44fb-9307-e16b60a772f2",
   "metadata": {},
   "source": [
    "# Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c075a98-ba48-431d-b1b7-65f957176b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(X_train_real, y_train_real, batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS, validation_data=(X_test_real, y_test_real), verbose=0,\n",
    "                    callbacks=[TqdmCallback(verbose=1)], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d16aa-e7bc-4e15-815b-40654f31d165",
   "metadata": {},
   "source": [
    "## Saving Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effd958-f015-43db-8ab5-cbd1b181a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = ((X_train_real, y_train_real), (X_test_real, y_test_real))\n",
    "models.save_metrics(dataset_name=dataset_name, train_type=train_type,\n",
    "                   epochs=EPOCHS, model=model, eval_data=eval_data, \n",
    "                   history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef397c39-dd79-4607-9ae3-296ccc266b0f",
   "metadata": {},
   "source": [
    "## Saving History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418abfa-3429-4a32-9c72-985ac2c1e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_path = Path.cwd() / f'reports/history/{dataset_name}/{MLConfig.TYPE_NAMES[train_type]}/E_{EPOCHS:03d}/'\n",
    "history_path.mkdir(parents=True, exist_ok=True)\n",
    "pd.DataFrame.from_dict(history.history).to_csv(history_path / f'{model.name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce32649-1d97-49f4-a7ba-ad596934533c",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6686283-7215-4367-bcfd-ec04f29a7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise.metric_plot(show_fig=True, history=history, dataset_name=dataset_name, \n",
    "                      savefig=False, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a3995-a3e4-47f9-87a7-2abc3f42709d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd74dc-77d9-473d-a535-cb185a8f9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(Path.cwd() / Path(f'reports/models/{dataset_name}/{MLConfig.TYPE_NAMES[train_type]}/E_{EPOCHS:03d}/{model.name}.h5'))\n",
    "# model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a152954-7ef9-4fcf-bc89-5f44123dc054",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(X_train_real, y_train_real)\n",
    "_, acc = model.evaluate(X_test_real, y_test_real)\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_train_real), axis=-1)\n",
    "report = classification_report(np.argmax(y_train_real, axis=1), y_pred)\n",
    "print(report)\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test_real), axis=-1)\n",
    "report = classification_report(np.argmax(y_test_real, axis=1), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bec417-0645-4b5b-8cc1-06b51c9e841c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
