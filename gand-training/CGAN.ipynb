{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3bda44-b63f-45db-a401-f0e56210c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist, fashion_mnist, cifar10\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Embedding, Dense, Reshape, Concatenate\n",
    "from keras.layers import Conv2D, LeakyReLU, Dropout, Flatten, Conv2DTranspose, BatchNormalization, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "import visualkeras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ones, zeros, expand_dims, vstack, asarray\n",
    "from numpy import linspace, arccos, clip, sin, cos, dot\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import rand, randn, randint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0559c-1b68-4593-a896-4ce83bbbeb58",
   "metadata": {},
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098d370-7a3f-4e84-bda0-a50172132981",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "\n",
    "OPT = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "DATASET_INFO = {\n",
    "    'mnist': {\n",
    "        'class_names': [str(i) for i in range(10)],\n",
    "        'input_shape': (28, 28, 1)\n",
    "    },\n",
    "    'fashion_mnist': {\n",
    "        'class_names': ['t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', \n",
    "                        'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'],\n",
    "        'input_shape': (28, 28, 1)\n",
    "    },\n",
    "    'cifar10':{\n",
    "        'class_names': ['airplane', 'car', 'bird', 'cat', 'deer', \n",
    "                        'dog', 'frog', 'horse', 'ship', 'truck'],\n",
    "        'input_shape': (32, 32, 3)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa5d6b-bf82-4394-8b88-224846166978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data=None, dataset_name='mnist', n=5, \n",
    "              save=False, show=False,\n",
    "              name=None, path='/plot_data/',\n",
    "              fontsize=14, axis='off', cmap='gray_r'):\n",
    "\n",
    "    images, labels = data\n",
    "    figsize = (n*2, n*2)\n",
    "    plt.figure(figsize=(figsize))\n",
    "    for i in range(n**2):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis(axis)\n",
    "        plt.imshow(images[i].squeeze(), cmap=cmap)\n",
    "        if labels is not None:\n",
    "            plt.title(DATASET_INFO[dataset_name]['class_names'][labels[i].squeeze()], fontsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        while name is None:\n",
    "            name = input(\"Enter name for figure: \")\n",
    "\n",
    "        file_path = cwd / Path('figures') / Path(path)\n",
    "        file_path.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(file_path.joinpath(str(name) + '.png'))\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3499b8a-f7c4-4bf9-833b-938a825e873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mnist.load_data()\n",
    "plot_data(data=train, show=True, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c962d-44c6-4e32-ad2e-e53310440fe0",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28773d57-c826-4719-9a41-47c627cd1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(dataset_name='mnist', \n",
    "                         n_classes=10, opt=OPT):\n",
    "\n",
    "    in_shape = DATASET_INFO[dataset_name]['input_shape']\n",
    "    \n",
    "    # LABEL INPUT\n",
    "    in_label = Input(shape=(1,), name='Input_Classes')\n",
    "    \n",
    "    # EMBEDDING FOR CATEGORICAL INPUT\n",
    "    li = Embedding(n_classes, 50, name='Embedding')(in_label)\n",
    "\n",
    "    n_nodes = in_shape[0] * in_shape[1] * 1\n",
    "    li = Dense(n_nodes, name='Dense')(li)\n",
    "\n",
    "    # RESHAPING TO MATCH THE DIMENSIONS OF THE IMAGE\n",
    "    li = Reshape((in_shape[0], in_shape[1], 1), name='Reshape')(li)\n",
    "    \n",
    "    # INPUT OF THE IMAGE\n",
    "    in_image = Input(shape=in_shape, name='Input_Image')\n",
    "    \n",
    "    # CONCATENATE LABEL TO THE CHANNELS\n",
    "    merge = Concatenate(name='Concatenate')([in_image, li])\n",
    "\n",
    "    # DOWNSAMPLE 1\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same', name='Conv2D_1')(merge)\n",
    "    fe = LeakyReLU(alpha=0.2, name='LeakyReLU_1')(fe)\n",
    "    if in_shape[2] == 3: assert fe.shape == (None, 16, 16, 128)\n",
    "    if in_shape[2] == 1: assert fe.shape == (None, 14, 14, 128)\n",
    "    \n",
    "    # DOWNSAMPLE 2\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same', name='Conv2D_2')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2, name='LeakyReLU_2')(fe)    \n",
    "    if in_shape[2] == 3: assert fe.shape == (None, 8, 8, 128)\n",
    "    if in_shape[2] == 1: assert fe.shape == (None, 7, 7, 128)\n",
    "\n",
    "    # DOWNSAMPLE 3\n",
    "    if in_shape[2] == 3:\n",
    "        fe = Conv2D(128, (3,3), strides=(2,2), padding='same', name='Conv2D_3')(fe)\n",
    "        fe = LeakyReLU(alpha=0.2, name='LeakyReLU_3')(fe)    \n",
    "        assert fe.shape == (None, 4, 4, 128)\n",
    "    \n",
    "    # FLATTEN\n",
    "    fe = Flatten(name='Flatten')(fe)\n",
    "    # DROPOUT\n",
    "    fe = Dropout(0.4, name='Dropout')(fe)\n",
    "    # OUTPUT\n",
    "    out_layer = Dense(1, activation='sigmoid', name='Classifier')(fe)\n",
    "    \n",
    "    model = Model([in_image, in_label], out_layer)                            \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=opt, \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = define_discriminator()\n",
    "plot_model(model, to_file='discriminator.png',\n",
    "           show_dtype=False, show_shapes=True, \n",
    "           show_layer_activations=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a1f25-9c61-44e2-a811-db15fde81529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(dataset_name='mnist',\n",
    "                     latent_dim=100, \n",
    "                     n_classes=10):\n",
    "\n",
    "    input_shape = DATASET_INFO[dataset_name]['input_shape']\n",
    "    in_label = Input(shape=(1,), name='Input_Classes')\n",
    "    li = Embedding(n_classes, 50, name='Embedding')(in_label)\n",
    "\n",
    "    node = 7 \n",
    "    if input_shape[2] == 3:\n",
    "        node = 4\n",
    "\n",
    "    n_nodes = node * node\n",
    "\n",
    "    li = Dense(n_nodes, name='Dense_Classes')(li)\n",
    "    li = Reshape((node, node, 1), name='Reshape_Classes')(li)\n",
    "\n",
    "    in_lat = Input(shape=(latent_dim,), name='Input_Noise')\n",
    "    \n",
    "    # FOUNDATION FOR THE IMAGE\n",
    "    n_nodes = 128 * node * node\n",
    "    gen = Dense(n_nodes, name='Dense_Image')(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2, name='LeakyReLU')(gen)\n",
    "    gen = Reshape((node, node, 128), name='Reshape_Image')(gen)\n",
    "    # merge image gen and label input\n",
    "    merge = Concatenate(name='Concatenate')([gen, li])\n",
    "\n",
    "    # UPSAMPLE 1\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', name='Conv2DTranspose_1')(merge)\n",
    "    gen = LeakyReLU(alpha=0.2, name='LeakyReLU_1')(gen)\n",
    "    if input_shape[2] == 1: assert gen.shape == (None, 14, 14, 128)\n",
    "    if input_shape[2] == 3: assert gen.shape == (None, 8, 8, 128)\n",
    "    \n",
    "    # UPSAMPLE 2\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', name='Conv2DTranspose_2')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2, name='LeakyReLU_2')(gen)\n",
    "    if input_shape[2] == 1: assert gen.shape == (None, 28, 28, 128)\n",
    "    if input_shape[2] == 3: assert gen.shape == (None, 16, 16, 128)\n",
    "\n",
    "    if input_shape[2] == 3:\n",
    "        gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', name='Conv2DTranspose_3')(gen)\n",
    "        gen = LeakyReLU(alpha=0.2, name='LeakyReLU_3')(gen)\n",
    "        if input_shape[2] == 3: assert gen.shape == (None, 32, 32, 128)\n",
    "    \n",
    "    # OUTPUT\n",
    "    out_layer = Conv2D(input_shape[2], (7,7), activation='tanh', padding='same', name='Conv2D')(gen)\n",
    "    assert out_layer.shape == (None, input_shape[0], input_shape[1], input_shape[2])\n",
    "    \n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    return model\n",
    "\n",
    "model = define_generator()\n",
    "plot_model(model, to_file='generator.png',\n",
    "           show_dtype=False, show_shapes=True, \n",
    "           show_layer_activations=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae1855-9f5b-4d4c-b0ef-edf9d9d3721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model ,opt=OPT):\n",
    "    d_model.trainable = False\n",
    "    \n",
    "    # GET NOISE AND LABELS FROM GENERATOR\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    \n",
    "    # IMAGE OUTPUT FROM GENERATOR\n",
    "    gen_output = g_model.output\n",
    "    \n",
    "    # CONNECTING IMAGE OUTPUT AND LABEL INPUT FROM THE GENERATOR -> DISCRIMINATOR\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    \n",
    "    # GAN MODEL -> TAKING IN NOISE AND LABEL AND OUTPUTS A CLASSIFICATION\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "model = define_gan(define_generator(), define_discriminator())\n",
    "plot_model(model, to_file='gan.png',\n",
    "           show_dtype=False, show_shapes=True, show_trainable=True,\n",
    "           show_layer_activations=True, expand_nested=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23de85c-5966-4a8a-8c7e-bce130070259",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4060f-6b57-4b00-81d6-a061750a316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples(dataset_name='mnist', \n",
    "                      dataset=mnist):\n",
    "    input_shape = DATASET_INFO[dataset_name]['input_shape']\n",
    "    \n",
    "    # Load the MNIST dataset\n",
    "    (x_train, y_train), (_, _) = dataset.load_data()\n",
    "    \n",
    "    # Reshape and normalize the input data\n",
    "    x_train = (x_train.reshape(x_train.shape[0], input_shape[0], input_shape[1], input_shape[2]).astype('float32') - 127.5) / 127.5\n",
    "\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac6bbc-9051-4d75-8ba0-cbe8fac1ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    # split into images and labels\n",
    "    images, labels = dataset\n",
    "    # choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be2364-8627-49bb-848d-a8ef80bff1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    # generate labels\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0296940-61dd-4ca7-a538-192be919f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = zeros((n_samples, 1))\n",
    "    return [images, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd769660-298f-4c79-8489-a80d6aef8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(g_model, epoch, path=None):\n",
    "    file_path = cwd / Path('models') / Path(path)\n",
    "    file_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    g_model.save(file_path / f'gen_model_e-{epoch+1:03d}.h5')\n",
    "    \n",
    "def summarise_performance(epoch, g_model, latent_dim, n_samples=100):\n",
    "    [X, labels], y = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    X = (X + 1) / 2.0\n",
    "\n",
    "    plot_data(data=(X, labels), dataset_name='mnist', save=True, \n",
    "              axis='off', path=f'{GAN_NAME}/images', \n",
    "              name=f'gen_image_e-{epoch+1:03d}', show=True)\n",
    "    \n",
    "    save_model(g_model, epoch, path=f'{GAN_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1351d-d717-440a-8457-058a0d714fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
    "    bat_per_epoch = dataset[0].shape[0] // n_batch\n",
    "    half_batch = n_batch // 2\n",
    "    hash = {\n",
    "        'd_loss1': [],\n",
    "        'd_loss2': [],\n",
    "        'g_loss': []\n",
    "    }\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epoch):\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "            \n",
    "            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels_fake], y_fake)\n",
    "            \n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            \n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "\n",
    "            print(f\">[{i+1:03d}/{n_epochs}] | Batch: [{j+1:03d}/{bat_per_epoch:03d}] | D-Real: {d_loss1:.3f} | D-Fake: {d_loss2:.3f} | G: {g_loss:.3f}\")\n",
    "\n",
    "            if j % 30 == 0:\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        hash['d_loss1'].append(d_loss1)\n",
    "        hash['d_loss2'].append(d_loss2)\n",
    "        hash['g_loss'].append(g_loss)\n",
    "        summarise_performance(i, g_model, latent_dim)\n",
    "    return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851002c-2bac-4c96-9680-15ab601710de",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "data_dataset = mnist\n",
    "dataset_name = 'mnist'\n",
    "\n",
    "d_model = define_discriminator(dataset_name=dataset_name)\n",
    "g_model = define_generator(latent_dim=latent_dim, dataset_name=dataset_name)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "\n",
    "GAN_NAME = f'cgan/{dataset_name}'\n",
    "dataset = load_real_samples(dataset=data_dataset, dataset_name=dataset_name)\n",
    "\n",
    "bat_per_epoch = dataset[0].shape[0] // 256\n",
    "half_batch = 256 // 2\n",
    "\n",
    "bat_per_epoch, half_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b52e0f-1cfc-44f0-a368-798f3d126bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash = train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256)\n",
    "pd.DataFrame.from_dict(hash).to_csv(f'{dataset_name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b56f4-0c78-4c63-a32f-7cecd759b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "data_dataset = fashion_mnist\n",
    "dataset_name = 'fashion_mnist'\n",
    "\n",
    "d_model = define_discriminator(dataset_name=dataset_name)\n",
    "g_model = define_generator(latent_dim=latent_dim, dataset_name=dataset_name)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "\n",
    "GAN_NAME = f'cgan/{dataset_name}'\n",
    "dataset = load_real_samples(dataset=data_dataset, dataset_name=dataset_name)\n",
    "\n",
    "bat_per_epoch = dataset[0].shape[0] // 256\n",
    "half_batch = 256 // 2\n",
    "\n",
    "bat_per_epoch, half_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2aad9f-bc0a-4785-b559-055f8de50554",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash = train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256)\n",
    "pd.DataFrame.from_dict(hash).to_csv(f'{dataset_name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf30a88-de3b-4432-bd3f-46d22229a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "data_dataset = cifar10\n",
    "dataset_name = 'cifar10'\n",
    "\n",
    "d_model = define_discriminator(dataset_name=dataset_name)\n",
    "g_model = define_generator(latent_dim=latent_dim, dataset_name=dataset_name)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "\n",
    "GAN_NAME = f'cgan/{dataset_name}'\n",
    "dataset = load_real_samples(dataset=data_dataset, dataset_name=dataset_name)\n",
    "\n",
    "bat_per_epoch = dataset[0].shape[0] // 256\n",
    "half_batch = 256 // 2\n",
    "\n",
    "bat_per_epoch, half_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc529177-a77f-41f6-ac1b-c0eecdd70ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash = train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256)\n",
    "pd.DataFrame.from_dict(hash).to_csv(f'{dataset_name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55801970-f4c5-434c-82dd-df9c3907e65b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf064c3-957d-425f-84bc-be64b7400731",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash = pd.read_csv('mnist.csv')\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "FONTSIZE = 20\n",
    "def update(frame):\n",
    "    axs[0].cla()\n",
    "    axs[1].cla()\n",
    "    \n",
    "    # end = (frame*divider) + start\n",
    "    \n",
    "    d_loss1 = hash.d_loss1[frame:frame+100]\n",
    "    d_loss2 = hash.d_loss2[frame:frame+100]\n",
    "    g_loss = hash.g_loss[frame:frame+100]\n",
    "\n",
    "    axs[0].plot(d_loss1, label='D-Real', linestyle='-')\n",
    "    axs[0].plot(d_loss2, label='D-Fake', linestyle='--')\n",
    "    axs[0].set_title('Discriminator Classification', fontsize=FONTSIZE-5)\n",
    "    axs[0].tick_params(axis='both', which='major', labelsize=FONTSIZE-7)\n",
    "    axs[0].tick_params(axis='both', which='minor', labelsize=FONTSIZE-7)\n",
    "    axs[0].legend(loc='upper right', fontsize=FONTSIZE-5)\n",
    "    \n",
    "    axs[1].plot(g_loss, label='G-Data', linestyle='-')\n",
    "    axs[1].set_title('Generator Model', fontsize=FONTSIZE-5)\n",
    "    axs[1].tick_params(axis='both', which='major', labelsize=FONTSIZE-7)\n",
    "    axs[1].tick_params(axis='both', which='minor', labelsize=FONTSIZE-7)\n",
    "    axs[1].legend(loc='upper right', fontsize=FONTSIZE-5)\n",
    "\n",
    "    fig.suptitle('cGAN Loss Values (MNIST)', fontsize=FONTSIZE)\n",
    "    fig.tight_layout()\n",
    "    print(f'[{frame+1}/{num_frames}]')\n",
    "    clear_output(wait=False)\n",
    "\n",
    "start_time = time()\n",
    "start = 5000\n",
    "divider = 30\n",
    "interval = 1\n",
    "\n",
    "num_frames = (len(hash) // divider)\n",
    "\n",
    "fps = 60\n",
    "# fps = 1000 / (num_frames * interval)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update, frames=num_frames, interval=interval)\n",
    "writer = animation.FFMpegWriter(fps=fps)\n",
    "anim.save('mnist-loss-animation.gif', writer=writer)\n",
    "end_time = time()\n",
    "\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a59cc-277b-42cb-99f1-354897d8eb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
